<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Multinomial Logistic Regression</title>
    <meta charset="utf-8" />
    <meta name="author" content="Prof. Maria Tackett" />
    <link rel="stylesheet" href="sta210-slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Multinomial Logistic Regression
## Prediction + model selection + conditions
### Prof. Maria Tackett

---




class: middle, center

## [Click for PDF of slides](22-multinom-logistic-pt2.pdf)



---

## Topics

- Predictions 

- Model selection 

- Checking conditions 

---


## NHANES Data

- [National Health and Nutrition Examination Survey](https://www.cdc.gov/nchs/nhanes/index.htm) is conducted by the National Center for Health Statistics (NCHS) 

- The goal is to *"assess the health and nutritional status of adults and children in the United States"*

- This survey includes an interview and a physical examination

---

## Health Rating vs. Age &amp; Physical Activity

- **Question**: Can we use a person's age and whether they do regular physical activity to predict their self-reported health rating?

- We will analyze the following variables: 

  + &lt;font class="vocab"&gt;`HealthGen`: &lt;/font&gt;Self-reported rating of participant's health in general.  Excellent, Vgood, Good, Fair, or Poor.
  
    + &lt;font class="vocab"&gt;`Age`: &lt;/font&gt;Age at time of screening (in years). Participants 80 or older were recorded as 80.
    
  + &lt;font class="vocab"&gt;`PhysActive`: &lt;/font&gt;Participant does moderate to vigorous-intensity sports, fitness or recreational activities
  


---

## Model in R




&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; y.level &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; std.error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; statistic &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p.value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Vgood &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.205 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.145 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 8.325 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Vgood &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Age &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.001 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.002 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.369 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.712 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Vgood &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; PhysActiveYes &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.321 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.093 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -3.454 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.001 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Good &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.948 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.141 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 13.844 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Good &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Age &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.002 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.002 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.977 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.329 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Good &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; PhysActiveYes &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.001 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.090 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -11.120 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Fair &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.915 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.164 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.566 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Fair &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Age &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.003 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.003 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.058 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.290 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Fair &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; PhysActiveYes &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.645 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.107 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -15.319 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Poor &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.521 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.290 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -5.238 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Poor &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Age &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.022 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.005 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4.522 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Poor &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; PhysActiveYes &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -2.656 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.236 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -11.275 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

class: middle, center

## Predictions

---

## Calculating probabilities

For categories `\(2,\ldots,K\)`, the probability that the `\(i^{th}\)` observation is in the `\(j^{th}\)` category is

`$$\hat{\pi}_{ij} = \frac{\exp\{\hat{\beta}_{0j} + \hat{\beta}_{1j}x_{i1} + \dots + \hat{\beta}_{pj}x_{ip}\}}{1 + \sum\limits_{k=2}^K \exp\{\hat{\beta}_{0k} + \hat{\beta}_{1k}x_{i1} + \dots \hat{\beta}_{pk}x_{ip}\}}$$`
&lt;br&gt; 

For the baseline category, `\(k=1\)`, we calculate the probability `\(\hat{\pi}_{i1}\)` as
`$$\hat{\pi}_{i1} = 1- \sum\limits_{k=2}^K \hat{\pi}_{ik}$$`

---

## NHANES: Predicted probabilities 
 
 .midi[

```r
#calculate predicted probabilities
pred_probs &lt;- as_tibble(predict(health_m, type = "probs")) %&gt;% 
                        mutate(obs_num = 1:n()) 
```
]


```
## # A tibble: 5 x 6
##   Excellent Vgood  Good   Fair    Poor obs_num
##       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;int&gt;
## 1    0.0705 0.244 0.451 0.198  0.0366      101
## 2    0.0702 0.244 0.441 0.202  0.0426      102
## 3    0.0696 0.244 0.427 0.206  0.0527      103
## 4    0.0696 0.244 0.427 0.206  0.0527      104
## 5    0.155  0.393 0.359 0.0861 0.00662     105
```

---

## Add predictions to original data

.midi[

```r
health_m_aug &lt;- inner_join(nhanes_adult, pred_probs, 
                           by = "obs_num") %&gt;%
  select(obs_num, everything())
```
]


```
## Rows: 6,710
## Columns: 10
## $ obs_num    &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…
## $ HealthGen  &lt;fct&gt; Good, Good, Good, Good, Vgood, Vgood, Vgood, Vgood, Vgood,…
## $ Age        &lt;int&gt; 34, 34, 34, 49, 45, 45, 45, 66, 58, 54, 50, 33, 60, 56, 56…
## $ PhysActive &lt;fct&gt; No, No, No, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, No,…
## $ Education  &lt;fct&gt; High School, High School, High School, Some College, Colle…
## $ Excellent  &lt;dbl&gt; 0.07069715, 0.07069715, 0.07069715, 0.07003173, 0.15547075…
## $ Vgood      &lt;dbl&gt; 0.2433979, 0.2433979, 0.2433979, 0.2444214, 0.3922335, 0.3…
## $ Good       &lt;dbl&gt; 0.4573727, 0.4573727, 0.4573727, 0.4372533, 0.3599639, 0.3…
## $ Fair       &lt;dbl&gt; 0.19568909, 0.19568909, 0.19568909, 0.20291032, 0.08585489…
## $ Poor       &lt;dbl&gt; 0.032843150, 0.032843150, 0.032843150, 0.045383332, 0.0064…
```

---

## Actual vs. Predicted Health Rating

- We can use our model to predict a person's perceived health rating given their age and whether they exercise

- For each observation, the predicted perceived health rating is the category with the highest predicted probability


```r
health_m_aug &lt;- health_m_aug %&gt;% 
  mutate(pred_health = predict(health_m, 
                               type = "class"))
```

---

## Actual vs. Predicted Health Rating

.midi[

```r
health_m_aug %&gt;% 
  count(HealthGen, pred_health, .drop = FALSE) %&gt;%
  pivot_wider(names_from = pred_health, values_from = n)
```

```
## # A tibble: 5 x 6
##   HealthGen Excellent Vgood  Good  Fair  Poor
##   &lt;fct&gt;         &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;
## 1 Excellent         0   550   223     0     0
## 2 Vgood             0  1376   785     0     0
## 3 Good              0  1255  1399     0     0
## 4 Fair              0   300   642     0     0
## 5 Poor              0    24   156     0     0
```
]



---

.question[
Why do you think no observations were predicted to have a rating of "Excellent", "Fair", or "Poor"?
]

--

&lt;img src="22-multinom-logistic-pt2_files/figure-html/unnamed-chunk-11-1.png" style="display: block; margin: auto;" /&gt;


---

class: middle, center

## Model selection 

---

## Comparing Nested Models 

- Suppose there are two models: 
    - Reduced Model includes predictors `\(x_1, \ldots, x_q\)`
    - Full Model includes predictors `\(x_1, \ldots, x_q, x_{q+1}, \ldots, x_p\)`

- We want to test the hypotheses
`$$\begin{aligned}&amp;H_0: \beta_{q+1} = \dots = \beta_p = 0 \\
&amp; H_a: \text{ at least 1 }\beta_j \text{ is not} 0\end{aligned}$$`

- To do so, we will use the .vocab[Drop-in-Deviance test] (very similar to logistic regression) 

---

## Add `Education` to the model? 

- We consider adding the participants' `Education` level to the model.
    - Education takes values `8thGrade`, `9-11thGrade`, `HighSchool`, `SomeCollege`, and `CollegeGrad`

- Models we're testing: 
    - Reduced Model: `Age`, `PhysActive`
    - Full Model: `Age`, `PhysActive`, `Education`
    
.alert[
`$$\begin{align}&amp;H_0: \beta_{9-11thGrade} = \beta_{HighSchool} = \beta_{SomeCollege} = \beta_{CollegeGrad} = 0\\
&amp;H_a: \text{ at least one }\beta_j \text{ is not equal to }0\end{align}$$`
]

---

## Add `Education` to the model? 

.alert[
`$$\begin{align}&amp;H_0: \beta_{9-11thGrade} = \beta_{HighSchool} = \beta_{SomeCollege} = \beta_{CollegeGrad} = 0\\
&amp;H_a: \text{ at least one }\beta_j \text{ is not equal to }0\end{align}$$`
]





```r
model_red &lt;- multinom(HealthGen ~ Age + PhysActive, 
               data = nhanes_adult)
model_full &lt;- multinom(HealthGen ~ Age + PhysActive + 
                         Education, 
               data = nhanes_adult)
```

---

## Add `Education` to the model? 





```r
anova(model_red, model_full, test = "Chisq") %&gt;%
  kable(format = "markdown")
```



|Model                        | Resid. df| Resid. Dev|Test   |    Df| LR stat.| Pr(Chi)|
|:----------------------------|---------:|----------:|:------|-----:|--------:|-------:|
|Age + PhysActive             |     25848|   16994.23|       |    NA|       NA|      NA|
|Age + PhysActive + Education |     25832|   16505.10|1 vs 2 |    16| 489.1319|       0|

--

At least one coefficient associated with `Education` is non-zero. Therefore, we will include `Education` in the model.

---

## Model with `Education`

.small[

|y.level |term                    | estimate| std.error| statistic| p.value| conf.low| conf.high|
|:-------|:-----------------------|--------:|---------:|---------:|-------:|--------:|---------:|
|Vgood   |(Intercept)             |    0.582|     0.301|     1.930|   0.054|   -0.009|     1.173|
|Vgood   |Age                     |    0.001|     0.003|     0.419|   0.675|   -0.004|     0.006|
|Vgood   |PhysActiveYes           |   -0.264|     0.099|    -2.681|   0.007|   -0.457|    -0.071|
|Vgood   |Education9 - 11th Grade |    0.768|     0.308|     2.493|   0.013|    0.164|     1.372|
|Vgood   |EducationHigh School    |    0.701|     0.280|     2.509|   0.012|    0.153|     1.249|
|Vgood   |EducationSome College   |    0.788|     0.271|     2.901|   0.004|    0.256|     1.320|
|Vgood   |EducationCollege Grad   |    0.408|     0.268|     1.522|   0.128|   -0.117|     0.933|
|Good    |(Intercept)             |    2.041|     0.272|     7.513|   0.000|    1.508|     2.573|
|Good    |Age                     |   -0.002|     0.003|    -0.651|   0.515|   -0.007|     0.003|
|Good    |PhysActiveYes           |   -0.758|     0.096|    -7.884|   0.000|   -0.946|    -0.569|
|Good    |Education9 - 11th Grade |    0.360|     0.275|     1.310|   0.190|   -0.179|     0.899|
|Good    |EducationHigh School    |    0.085|     0.247|     0.345|   0.730|   -0.399|     0.569|
|Good    |EducationSome College   |   -0.011|     0.239|    -0.047|   0.962|   -0.480|     0.457|
|Good    |EducationCollege Grad   |   -0.891|     0.236|    -3.767|   0.000|   -1.354|    -0.427|
|Fair    |(Intercept)             |    2.116|     0.288|     7.355|   0.000|    1.552|     2.680|
|Fair    |Age                     |    0.000|     0.003|     0.107|   0.914|   -0.006|     0.006|
|Fair    |PhysActiveYes           |   -1.191|     0.115|   -10.367|   0.000|   -1.416|    -0.966|
|Fair    |Education9 - 11th Grade |   -0.224|     0.279|    -0.802|   0.422|   -0.771|     0.323|
|Fair    |EducationHigh School    |   -0.832|     0.252|    -3.307|   0.001|   -1.326|    -0.339|
|Fair    |EducationSome College   |   -1.343|     0.246|    -5.462|   0.000|   -1.825|    -0.861|
|Fair    |EducationCollege Grad   |   -2.509|     0.253|    -9.913|   0.000|   -3.005|    -2.013|
|Poor    |(Intercept)             |   -0.200|     0.411|    -0.488|   0.626|   -1.005|     0.605|
|Poor    |Age                     |    0.018|     0.005|     3.527|   0.000|    0.008|     0.028|
|Poor    |PhysActiveYes           |   -2.267|     0.242|    -9.377|   0.000|   -2.741|    -1.793|
|Poor    |Education9 - 11th Grade |   -0.360|     0.353|    -1.020|   0.308|   -1.053|     0.332|
|Poor    |EducationHigh School    |   -1.150|     0.334|    -3.438|   0.001|   -1.805|    -0.494|
|Poor    |EducationSome College   |   -1.073|     0.316|    -3.399|   0.001|   -1.692|    -0.454|
|Poor    |EducationCollege Grad   |   -2.322|     0.366|    -6.342|   0.000|   -3.039|    -1.604|
]

---

## Compare NHANES models using AIC

.midi[

```r
glance(model_red)$AIC
```

```
## [1] 17018.23
```

```r
glance(model_full)$AIC
```

```
## [1] 16561.1
```
]

--

Use the `step()` function to do model selection with AIC as the selection criteria

---

class: middle, center

## Checking conditions

---

## Assumptions for multinomial logistic regression

We want to check the following assumptions for the multinomial logistic regression model: 

1. .vocab[Linearity]: Is there a linear relationship between the log-odds and the predictor variables?

2. .vocab[Randomness]: Was the sample randomly selected? Or can we reasonably treat it as random? 

3. .vocab[Independence]: There is no obvious relationship between observations

---

## Checking linearity 

Similar to logistic regression, we will check linearity by examining empirical logit plots between each level of the predictor and the quantitative predictor variables.

.small[

```r
nhanes_adult &lt;- nhanes_adult %&gt;%
  mutate(Excellent = factor(if_else(HealthGen == "Excellent", "1", "0")), 
         Vgood = factor(if_else(HealthGen == "Vgood", "1", "0")), 
         Good = factor(if_else(HealthGen == "Good", "1", "0")), 
         Fair = factor(if_else(HealthGen == "Fair", "1", "0")), 
         Poor = factor(if_else(HealthGen == "Poor", "1", "0"))
  )
```
]

---

## Checking linearity

.small[

```r
library(Stat2Data)
```


```r
par(mfrow = c(2,1))
emplogitplot1(Excellent ~ Age, data = nhanes_adult, ngroups = 5, main = "Excellent vs. Age")
emplogitplot1(Vgood ~ Age, data = nhanes_adult, ngroups = 5, main = "Vgood vs. Age")
```

&lt;img src="22-multinom-logistic-pt2_files/figure-html/unnamed-chunk-20-1.png" style="display: block; margin: auto;" /&gt;
]

---

## Checking linearity 

.small[

```r
par(mfrow = c(2,1))
emplogitplot1(Good ~ Age, data = nhanes_adult, ngroups = 5, main = "Good vs. Age")
emplogitplot1(Fair ~ Age, data = nhanes_adult, ngroups = 5, main = "Fair vs. Age")
```

&lt;img src="22-multinom-logistic-pt2_files/figure-html/unnamed-chunk-21-1.png" style="display: block; margin: auto;" /&gt;
]

---

## Checking linearity 

.small[

```r
emplogitplot1(Poor ~ Age, data = nhanes_adult, ngroups = 5, main = "Poor vs. Age")
```

&lt;img src="22-multinom-logistic-pt2_files/figure-html/unnamed-chunk-22-1.png" style="display: block; margin: auto;" /&gt;
]

--

✅ The linearity condition is satisfied. There is a linear relationship between the empirical logit and the quantitative predictor variable, Age.

---

## Checking randomness

We can check the randomness condition based on the context of the data and how the observations were collected. 

- Was the sample randomly selected?

- If the sample was not randomly selected, ask whether there is reason to believe the observations in the sample differ systematically from the population of interest. 

--

✅ The randomness condition is satisfied. We do not have reason to believe that the participants in this study differ systematically from adults in the U.S..


---

## Checking independence


We can check the independence condition based on the context of the data and how the observations were collected.

Independence is most often violated if the data were collected over time or there is a strong spatial relationship between the observations. 

--

✅ The independence condition is satisfied. It is reasonable to conclude that the participants' health and behavior characteristics are independent of one another.


---

## Recap


- Predictions 

- Model selection 

- Checking conditions
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"slideNumberFormat": "%current%",
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
