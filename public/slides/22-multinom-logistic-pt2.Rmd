---
title: "Multinomial Logistic Regression"
subtitle: "Prediction + model selection + conditions"
author: "Prof. Maria Tackett"
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: "sta210-slides.css"
    logo: img/sta199-sticker-icon.png
    lib_dir: libs/font-awesome
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      slideNumberFormat: "%current%" 
      ratio: "16:9"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, echo=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
	fig.align = "center",
	fig.height =5,
	fig.width = 8,
	message = FALSE,
	warning = FALSE,
	echo = FALSE
)
```

class: middle, center

## [Click for PDF of slides](22-multinom-logistic-pt2.pdf)

```{r,echo=F}
library(tidyverse)
library(knitr)
library(broom)
library(pROC) 
library(kableExtra)
library(patchwork)
```

---

## Topics

- Predictions 

- Model selection 

- Checking conditions 

---


## NHANES Data

- [National Health and Nutrition Examination Survey](https://www.cdc.gov/nchs/nhanes/index.htm) is conducted by the National Center for Health Statistics (NCHS) 

- The goal is to *"assess the health and nutritional status of adults and children in the United States"*

- This survey includes an interview and a physical examination

---

## Health Rating vs. Age & Physical Activity

- **Question**: Can we use a person's age and whether they do regular physical activity to predict their self-reported health rating?

- We will analyze the following variables: 

  + <font class="vocab">`HealthGen`: </font>Self-reported rating of participant's health in general.  Excellent, Vgood, Good, Fair, or Poor.
  
    + <font class="vocab">`Age`: </font>Age at time of screening (in years). Participants 80 or older were recorded as 80.
    
  + <font class="vocab">`PhysActive`: </font>Participant does moderate to vigorous-intensity sports, fitness or recreational activities
  
```{r echo = F}
library(NHANES)

nhanes_adult <- NHANES %>%
  filter(Age >= 18, !is.na(HealthGen), !is.na(Age), !is.na(PhysActive)) %>%
  select(HealthGen, Age, PhysActive, Education) %>%
  mutate(obs_num = 1:n())
```

---

## Model in R


```{r, echo = F, results = "hide"}
library(nnet)
health_m <- multinom(HealthGen ~ Age + PhysActive, 
                     data = nhanes_adult)
```

```{r echo = F}
tidy(health_m) %>%
  kable(digits = 3)
```

---

class: middle, center

## Predictions

---

## Calculating probabilities

For categories $2,\ldots,K$, the probability that the $i^{th}$ observation is in the $j^{th}$ category is

$$\hat{\pi}_{ij} = \frac{\exp\{\hat{\beta}_{0j} + \hat{\beta}_{1j}x_{i1} + \dots + \hat{\beta}_{pj}x_{ip}\}}{1 + \sum\limits_{k=2}^K \exp\{\hat{\beta}_{0k} + \hat{\beta}_{1k}x_{i1} + \dots \hat{\beta}_{pk}x_{ip}\}}$$
<br> 

For the baseline category, $k=1$, we calculate the probability $\hat{\pi}_{i1}$ as
$$\hat{\pi}_{i1} = 1- \sum\limits_{k=2}^K \hat{\pi}_{ik}$$

---

## NHANES: Predicted probabilities 
 
 .midi[
```{r echo = T}
#calculate predicted probabilities
pred_probs <- as_tibble(predict(health_m, type = "probs")) %>% 
                        mutate(obs_num = 1:n()) 
```
]

```{r}
pred_probs %>%
  slice(101:105)
```

---

## Add predictions to original data

.midi[
```{r echo = T}
health_m_aug <- inner_join(nhanes_adult, pred_probs, 
                           by = "obs_num") %>%
  select(obs_num, everything())
```
]

```{r}
health_m_aug %>% 
  glimpse()
```

---

## Actual vs. Predicted Health Rating

- We can use our model to predict a person's perceived health rating given their age and whether they exercise

- For each observation, the predicted perceived health rating is the category with the highest predicted probability

```{r echo = T}
health_m_aug <- health_m_aug %>% 
  mutate(pred_health = predict(health_m, 
                               type = "class"))
```

---

## Actual vs. Predicted Health Rating

.midi[
```{r echo  = T}
health_m_aug %>% 
  count(HealthGen, pred_health, .drop = FALSE) %>%
  pivot_wider(names_from = pred_health, values_from = n)
```
]



---

.question[
Why do you think no observations were predicted to have a rating of "Excellent", "Fair", or "Poor"?
]

--

```{r}
ggplot(data = nhanes_adult, aes(x = HealthGen)) + 
  geom_bar() +
  labs(title = "Self-reported rating of overall health")
```


---

class: middle, center

## Model selection 

---

## Comparing Nested Models 

- Suppose there are two models: 
    - Reduced Model includes predictors $x_1, \ldots, x_q$
    - Full Model includes predictors $x_1, \ldots, x_q, x_{q+1}, \ldots, x_p$

- We want to test the hypotheses
$$\begin{aligned}&H_0: \beta_{q+1} = \dots = \beta_p = 0 \\
& H_a: \text{ at least 1 }\beta_j \text{ is not} 0\end{aligned}$$

- To do so, we will use the .vocab[Drop-in-Deviance test] (very similar to logistic regression) 

---

## Add `Education` to the model? 

- We consider adding the participants' `Education` level to the model.
    - Education takes values `8thGrade`, `9-11thGrade`, `HighSchool`, `SomeCollege`, and `CollegeGrad`

- Models we're testing: 
    - Reduced Model: `Age`, `PhysActive`
    - Full Model: `Age`, `PhysActive`, `Education`
    
.alert[
$$\begin{align}&H_0: \beta_{9-11thGrade} = \beta_{HighSchool} = \beta_{SomeCollege} = \beta_{CollegeGrad} = 0\\
&H_a: \text{ at least one }\beta_j \text{ is not equal to }0\end{align}$$
]

---

## Add `Education` to the model? 

.alert[
$$\begin{align}&H_0: \beta_{9-11thGrade} = \beta_{HighSchool} = \beta_{SomeCollege} = \beta_{CollegeGrad} = 0\\
&H_a: \text{ at least one }\beta_j \text{ is not equal to }0\end{align}$$
]

```{r echo = F}
nhanes_adult <- nhanes_adult %>%
  drop_na()
```


```{r echo = T, eval = F}
model_red <- multinom(HealthGen ~ Age + PhysActive, 
               data = nhanes_adult)
model_full <- multinom(HealthGen ~ Age + PhysActive + 
                         Education, 
               data = nhanes_adult)
```

---

## Add `Education` to the model? 

```{r results = "hide"}
model_red <- multinom(HealthGen ~ Age + PhysActive, 
               data = nhanes_adult)
model_full <- multinom(HealthGen ~ Age + PhysActive + Education, 
               data = nhanes_adult)
```


```{r echo = T}
anova(model_red, model_full, test = "Chisq") %>%
  kable(format = "markdown")
```

--

At least one coefficient associated with `Education` is non-zero. Therefore, we will include `Education` in the model.

---

## Model with `Education`

.small[
```{r echo = F}
tidy(model_full, conf.int = T) %>%
  kable(format = "markdown", digits = 3)
```
]

---

## Compare NHANES models using AIC

.midi[
```{r echo = T}
glance(model_red)$AIC
glance(model_full)$AIC
```
]

--

Use the `step()` function to do model selection with AIC as the selection criteria

---

class: middle, center

## Checking conditions

---

## Assumptions for multinomial logistic regression

We want to check the following assumptions for the multinomial logistic regression model: 

1. .vocab[Linearity]: Is there a linear relationship between the log-odds and the predictor variables?

2. .vocab[Randomness]: Was the sample randomly selected? Or can we reasonably treat it as random? 

3. .vocab[Independence]: There is no obvious relationship between observations

---

## Checking linearity 

Similar to logistic regression, we will check linearity by examining empirical logit plots between each level of the response and the quantitative predictor variables.

.small[
```{r echo = T}
nhanes_adult <- nhanes_adult %>%
  mutate(Excellent = factor(if_else(HealthGen == "Excellent", "1", "0")), 
         Vgood = factor(if_else(HealthGen == "Vgood", "1", "0")), 
         Good = factor(if_else(HealthGen == "Good", "1", "0")), 
         Fair = factor(if_else(HealthGen == "Fair", "1", "0")), 
         Poor = factor(if_else(HealthGen == "Poor", "1", "0"))
  )
```
]

---

## Checking linearity

.small[
```{r echo = T}
library(Stat2Data)
```

```{r echo = T}
par(mfrow = c(2,1))
emplogitplot1(Excellent ~ Age, data = nhanes_adult, ngroups = 5, main = "Excellent vs. Age")
emplogitplot1(Vgood ~ Age, data = nhanes_adult, ngroups = 5, main = "Vgood vs. Age")
```
]

---

## Checking linearity 

.small[
```{r echo = T}
par(mfrow = c(2,1))
emplogitplot1(Good ~ Age, data = nhanes_adult, ngroups = 5, main = "Good vs. Age")
emplogitplot1(Fair ~ Age, data = nhanes_adult, ngroups = 5, main = "Fair vs. Age")
```
]

---

## Checking linearity 

.small[
```{r echo = T}
emplogitplot1(Poor ~ Age, data = nhanes_adult, ngroups = 5, main = "Poor vs. Age")
```
]

--

`r emo::ji("white_check_mark")` The linearity condition is satisfied. There is a linear relationship between the empirical logit and the quantitative predictor variable, Age.

---

## Checking randomness

We can check the randomness condition based on the context of the data and how the observations were collected. 

- Was the sample randomly selected?

- If the sample was not randomly selected, ask whether there is reason to believe the observations in the sample differ systematically from the population of interest. 

--

`r emo::ji("white_check_mark")` The randomness condition is satisfied. We do not have reason to believe that the participants in this study differ systematically from adults in the U.S..


---

## Checking independence


We can check the independence condition based on the context of the data and how the observations were collected.

Independence is most often violated if the data were collected over time or there is a strong spatial relationship between the observations. 

--

`r emo::ji("white_check_mark")` The independence condition is satisfied. It is reasonable to conclude that the participants' health and behavior characteristics are independent of one another.


---

## Recap


- Predictions 

- Model selection 

- Checking conditions 