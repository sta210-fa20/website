---
title: "Multiple Linear Regression"
subtitle: "Special Predictors & Assumptions"
author: "Prof. Maria Tackett"
date: "02.12.20"
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: "sta210-slides.css"
    logo: img/sta210-sticker-icon.png
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      slideNumberFormat: "%current%"
---

```{r setup, include=FALSE, echo=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
	fig.align = "center",
	fig.height = 3.5,
	message = FALSE,
	warning = FALSE, 
	dpi = 300
)
```

class: middle, center

### [Click for PDF of slides](08-assumptions.pdf)

---

### Announcements

- HW 02 **due TODAY at 11:59p**

- HW 03 will be assigned Monday and due **Feb 24**

- [Analysis of variance questions](https://github.com/sta210-sp20/muddiest-point-questions/blob/master/anova.md)

---

### Today's agenda 

- Special predictors

- Checking assumptions 

```{r echo = F}
library(tidyverse)
library(knitr)
library(broom)
library(cowplot) # use plot_grid function
```

---

### Peer-to-peer lender

Today's data is a sample of about 9900 applications to a peer-to-peer lending club. The full data is in the `loans_full_schema` dataframe in the `openintro` package.

```{r}
# loan50 dataset from the openintro package
loans <- read_csv("data/loans.csv") %>%
  mutate(bankruptcy = as.factor(bankruptcy))
glimpse(loans)
```

---

### Variables

**Predictors**
- .vocab[`verified_income`]: Whether borrower's income source and amount have been verified (`Not Verified`, `Source Verified`, `Verified`)
- .vocab[`debt_to_income`]: Debt-to-income ratio, i.e. the percentage of a borrower's total debt divided by their total income
- .vocab[`bankruptcy`]: Indicator of whether borrower has had a bankruptcy in the past (`0`: No, `1`: Yes)
- .vocab[`term`]: Length of the loan in months
- .vocab[`credit_util`]: What fraction of total credit a borrower is utilizing, i.e. total credit utilizied divided by total credit limit

**Response**
- .vocab[`interest_rate`]: Interest rate for the loan

---

### Response variable, `interest_rate`

```{r echo = F}
ggplot(data = loans, aes(x = interest_rate)) +
  geom_histogram() + 
  labs(x = "Interest rate", 
       title = "Distribution of interest rate")
```

---

### Predictor variables 

```{r echo = F, fig.height = 6, fig.width = 9}
library(patchwork)

p1 <- ggplot(data = loans, aes(x = verified_income)) +
  geom_bar() +
  labs(title = "Verified Income", 
       x = "", y = "") +
  coord_flip()

p2 <- ggplot(data = loans, aes(x = debt_to_income)) +
  geom_histogram() + 
  labs(title = "Debt to income ratio",
       x = "", y = "")

p3 <- ggplot(data = loans, aes(x = bankruptcy)) +
  geom_bar() + 
  labs(title = "Past Bankruptcy",
       x = "", y = "")

p4 <- ggplot(data = loans, aes(x = term)) +
  geom_histogram() + 
  labs(title = "Loan term length", 
       x = "", y = "")

p5 <- ggplot(data = loans, aes(x = credit_util)) +
  geom_histogram() + 
  labs(title = "Credit Utilization", 
       x = "", y = "")

p1 + p2 + p3 + p4 + p5
```

---

### Response vs. Predictors

```{r echo = F, fig.height = 6, fig.width = 9}
p1 <- ggplot(data = loans, aes(x = verified_income, y = interest_rate)) +
  geom_boxplot() + 
  labs()

p2 <- ggplot(data = loans, aes(x = debt_to_income, y = interest_rate)) +
  geom_point(alpha = 0.2) + 
  labs(y = "")


p3 <- ggplot(data = loans, aes(x = bankruptcy, y = interest_rate)) +
  geom_boxplot() + 
  labs(y = "")


p4 <- ggplot(data = loans, aes(x = term, y = interest_rate)) +
  geom_point(alpha = 0.2) + 
  labs(y = "")


p5 <- ggplot(data = loans, aes(x = credit_util, y = interest_rate)) +
  geom_point(alpha = 0.2) + 
  labs(y = "")


p1 + p2 + p3 + p4 + p5
```

---

### Regression Model 

```{r echo = F}
int_model <- lm(interest_rate ~ verified_income + debt_to_income + bankruptcy + term + credit_util, data = loans)
tidy(int_model, conf.int = T) %>% kable(format = "markdown", digits = 3)
```

---

class: middle, center

## Special Predictors

---

### Interpreting the Intercept 

```{r echo=FALSE}
kable(tidy(int_model),format = "markdown", digits = 3)
```

.question[
- Based on our model, what subset of borrowers do we expect to have an interest rate of 2.233%? In other words, what subset of borrowers are included in the intercept?

- Is this interpretation meaningful? Why or why not?
]

---


### Mean-Centered Variables

- To have a meaningful interpretation of the intercept, use **mean-centered** predictor variables in the model (quantitative predictors only)

- A <font class = "vocab">mean-centered variable</font> is calculated by subtracting the mean from each value of the variable, i.e. $$x_{ip} - \bar{x}_{.p}$$

- Now the intercept is interpreted as the expected value of the response at the mean value of all quantitative predictors

---

### Loans: mean-centered variables

.small[
```{r}
loans <- loans %>%
  mutate(debt_inc_cent = debt_to_income - mean(debt_to_income), 
         term_cent = term - mean(term), 
         credit_util_cent = credit_util - mean(credit_util))
```
]

.pull-left[
```{r,echo=F}
ggplot(data = loans, aes(x = credit_util)) + 
  geom_histogram() + 
labs(title = "Credit Utilization", x = "", y = "")
```
]

.pull-right[
```{r echo = F}
ggplot(data = loans, aes(x = credit_util_cent)) + 
  geom_histogram() + 
labs(title = "Mean-Centered Credit Util.", x = "", y = "")
```
]

---

### In-class exercise
.small[
```{r echo = F}
tidy(int_model) %>%
  kable(format = "markdown", digits = 3)
```
]

.question[
- Go to http://bit.ly/sta210-sp20-mean-center and describe how the model would change if `debt_inc_cent`, `term_cent`, and `credit_util_cent` were used in the model instead of the original versions of these variables.
]

```{r echo = F}
library(countdown)
countdown(minutes = 3, seconds = 0, update_every = 1, warn_when = 30)
```

---

### How model changes with mean-centered variables

```{r echo = F}
cent_model <- lm(interest_rate ~ verified_income + debt_inc_cent + bankruptcy + term_cent + credit_util_cent, data = loans)
tidy(cent_model, conf.int = T) %>% 
  kable(format = "markdown" , digits = 3)
```



```{r}
ggplot(data = loans, aes(x = credit_util_cent, y = interest_rate)) +
  geom_point()
```




---

### Indicator (dummy) variables


- Suppose there is a categorical variable with $k$ levels (categories)

- Make $k$ indicator variables (also known as dummy variables)

- Use $k-1$ of the indicator variables in the model
    - Can't uniquely estimate all $k$ variables at once if the intercept is in the model
    
- Level that doesn't have a term in the model is called the <font class="vocab3">baseline</font>

- Coefficients interpreted as the change in the mean of the response over the baseline

---

### Indicator variables: $k = 2$

```{r echo = F}
cent_model <- lm(interest_rate ~ verified_income + debt_inc_cent + bankruptcy + term_cent + credit_util_cent, data = loans)
tidy(cent_model, conf.int = T) %>% 
  kable(format = "markdown" , digits = 3)
```

Interpreting `bankruptcy` in the model: 

---

### Indicator variables: $k > 2$

```{r echo = F}
cent_model <- lm(interest_rate ~ verified_income + debt_inc_cent + bankruptcy + term_cent + credit_util_cent, data = loans)
tidy(cent_model, conf.int = T) %>% kable(format = "markdown", digits = 3)
```

Interpreting `verified_income` in the model: 

---

### Interaction Terms

- **Case**: Relationship of the predictor variable with the response depends on the value of another predictor variable
  + This is an .vocab[interaction effect]
  
- Create a new interaction variable that is one predictor variable times the other in the interaction 

-  **Good Practice**: When including an interaction term, also *include the associated <u>main effects</u>* (each predictor variable on its own) even if their coefficients are not statistically significant

---

### Add interaction term

```{r}
model_w_int <- lm(interest_rate ~ verified_income + debt_inc_cent + 
                   bankruptcy + term_cent + credit_util_cent +
                   debt_inc_cent * verified_income,
                 data = loans)
```

```{r echo = F}
tidy(model_w_int, conf.int = T) %>% kable(format = "markdown", digits = 3)
```

---

class: middle, center

### Checking model assumptions 

---

### Assumptions 

Inference on the regression coefficients and predictions are reliable only when the regression assumptions are reasonably satisfied: 

1. <font class="vocab">Linearity: </font> Response variable has a linear relationship with the predictor variables in the model

2. <font class="vocab">Constant Variance: </font>The regression variance is the same for all set of predictor variables $(x_1, \ldots, x_p)$

3. <font class="vocab">Normality: </font> For a given set of predictors $(x_1, \ldots, x_p)$, the response, $y$, follows a Normal distribution around its mean 

4. <font class="vocab">Independence: </font>All observations are independent

--
.alert[
We will use plots of the residuals to check these assumptions 
]

---

### Checking linearity assumption

- Make the following plots: 
  - Plot the residuals vs. the predicted (fitted) values
  - Plot the residuals vs. each predictor variable

- These plots should have no systematic / obvious pattern, i.e there should be no apparent structure 

- A systematic pattern may suggestion that interactions or higher-order terms (like quadratic terms) are required.

---

### Checking constant variance assumption 

- Make a plot of the residuals vs. the predicted (fitted) values

- The height of the cloud of points should be constant as you go from left to right on the plot

---

### Checking normality assumption 

- Make the following plots: 
    - Histogram of the residuals
    - Normal QQ-Plot of the residuals 

- The histogram should be approximately unimodal and symmetric. 

- The points on the Normal QQ-Plot should generally follow a straight diagonal line
    
---

### Checking independence assumption 

- In the indepednece assumption, we assume the residuals are not correlated

- If your data were collected over time, plot the residuals in time order 

- There should be no pattern in the plot.
  - A cyclical pattern indicates the residuals are correlated, a violation of the assumption. 
  
- Can generally conclude this assumption is resonably met unless there are clear violations

---

### `augment`

- Use the .vocab[`augment`] function in the **broom** package to calculate residuals, predicted values, and other model diagnostics 

```{r}
loans_aug <- augment(model_w_int)
glimpse(loans_aug)
```

---

### Check linearity: Residuals vs. Predicted

```{r}
ggplot(data = loans_aug, aes(x = .fitted, y = .resid)) +
  geom_point(alpha = 0.3) + 
  geom_hline(yintercept = 0, color = "red") +
  labs(x = "Predicted", y = "Residuals", 
       title = "Residuals vs. Predicted")
```

---

### Check linearity: Residuals vs. Predictors

```{r echo = F, fig.height = 6, fig.width = 9}
p2 <- ggplot(data = loans_aug, aes(x = verified_income, y = .resid)) +
  geom_boxplot() + 
  geom_hline(yintercept = 0, color = "red") +
  labs(y = "Residuals")

p3 <- ggplot(data = loans_aug, aes(x = debt_inc_cent, y = .resid)) +
  geom_point(alpha = 0.3) + 
  geom_hline(yintercept = 0, color = "red") +
  labs(x = "Debt to Income", y = "Residuals")

p4 <- ggplot(data = loans_aug, aes(x = bankruptcy, y = .resid)) +
  geom_boxplot() + 
  geom_hline(yintercept = 0, color = "red") +
  labs(y = "Residuals")

p5 <- ggplot(data = loans_aug, aes(x = term_cent, y = .resid)) +
  geom_point(alpha = 0.3) + 
  geom_hline(yintercept = 0, color = "red") +
  labs(x = "Term", y = "Residuals")

p6 <- ggplot(data = loans_aug, aes(x = credit_util_cent, y = .resid)) +
  geom_point(alpha = 0.3) + 
  geom_hline(yintercept = 0, color = "red") +
  labs(x = "Credit Utility", y = "Residuals")

p2 + p3 + p4 + p5 + p6
```

---

### Check constant variance

```{r echo  = F}
ggplot(data = loans_aug, aes(x = .fitted, y = .resid)) +
  geom_point(alpha = 0.3) + 
  geom_hline(yintercept = 0, color = "red") +
  labs(x = "Predicted", y = "Residuals", 
       title = "Residuals vs. Predicted")
```


---

### Check Normality


```{r echo = F, fig.height = 6, fig.width = 9}
p1 <- ggplot(data = loans_aug, aes(x = .resid)) +
  geom_histogram() +
  labs(x = "Residuals", y = "", 
       title = "Distribution of Residuals")

p2 <- ggplot(data = loans_aug, aes(sample = .resid)) +
  stat_qq() + 
  stat_qq_line() + 
  labs(title = "Normal QQ-Plot of Residuals")

p1 + p2 #using patchwork package
```


---

### Checking independence

Can check residuals versus observation number if you think there is some structure / order to the dataset. Below is the code for this dataset:

.small[
```{r}
loans_aug <- loans_aug %>%
  mutate(obs_num = 1:nrow(loans_aug))
```

```{r, fig.height = 2.5}
ggplot(data = loans_aug, aes(x = obs_num, y = .resid)) + 
  geom_point(alpha = 0.3) +
  labs(x = "Observation Number", y = "Residuals", 
       title = "Residuals vs. Observation Number")
```
]

---

### Use EDA but don't solely rely on it

- Look at a scatterplot of the response variable vs. each of the predictor variables in the exploratory data analysis before calculating the regression model 

- This is a good way to check for obvious departures from linearity or constant variance

- This is **<u>not</u>** definitive, but it can give you an indication early on if you might need to use interactions, higher-order terms, or do a transformation (more on that next week)




